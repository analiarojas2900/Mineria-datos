# -*- coding: utf-8 -*-
"""Evaluacion3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DnQN0nNpl89kumlPUIL4XSSwYyFr0hla

# Carga de Datos
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns

data_frame = pd.read_csv("weatherAUS.csv")

data_frame.head()

"""# Estadísticos del dataframe"""

# Tamaño del data frame
display(data_frame.shape)

# Información estadística del dataframe
data_frame.describe()

#Revisión de los tipos de datos
data_frame.dtypes

# Considerando solo las columnas tipo object

data_frame.describe(include=object)

"""# Coeficiente de Correlación"""

# Convertir la columna 'Date' al tipo de datos de fecha
data_frame['Date'] = pd.to_datetime(data_frame['Date'])

Coef = data_frame[["Date","Location","MinTemp","MaxTemp","Rainfall","Evaporation","Sunshine","WindGustDir","WindGustSpeed","WindDir9am","Humidity3pm","Pressure9am","Pressure3pm","Cloud9am","Cloud3pm","Temp9am","Temp3pm","RISK_MM"]]
coefes = Coef.rename(columns={"Date":"Fecha","Location":"Ubicacion","MinTemp":"MinTemp","MaxTemp":"MaxTemp","Rainfall":"Lluvia","Evaporation":"Evaporacion","Sunshine":"Sol","WindGustDir":"DirRafaga","WindGustSpeed":"VelRafaga","WindDir9am":"Dir9am","Humidity3pm":"Hum3pm","Pressure9am":"Pres9am","Pressure3pm":"Pre3pm","Cloud9am":"Nub9am","Cloud3pm":"Nub3pm","Temp9am":"Temp9am","Temp3pm":"Temp3pm","RISK_MM":"Riesgo_MM"})
coefes

#OPCION 1(Recomendada)
# Seleccionar todas las columnas que no sean numéricas
columnas_no_numericas = coefes.select_dtypes(exclude=['float64', 'int64']).columns

# Eliminar las columnas no numéricas del DataFrame
coefes = coefes.drop(columns=columnas_no_numericas)

# Iterar sobre todas las columnas del DataFrame
for columna in coefes.columns:
    # Verificar si la columna contiene valores de tipo string
    if coefes[columna].dtype == 'object':
        # Intentar convertir los valores de la columna a números
        coefes[columna] = pd.to_numeric(coefes[columna], errors='coerce')

#Correlacion Lineal
corr = coefes.corr()
print(corr)

# Importa la librería Matplotlib
import matplotlib.pyplot as plt

# Configura el tamaño de la figura
plt.figure(figsize=(9, 9))

# Crea el gráfico de calor (heatmap) con Matplotlib
# 'corr' es una matriz de correlación que se pasa al método imshow
# 'cmap' define el mapa de colores, 'coolwarm' en este caso
# 'interpolation' determina cómo se interpola el color entre los píxeles
# 'vmin' y 'vmax' establecen los límites para el rango de colores, de -1 a +1
plt.imshow(corr, cmap="coolwarm", interpolation='nearest', vmin=-1, vmax=+1)

# Añade una barra de color para indicar la escala de valores
plt.colorbar()

# Añade los valores de correlación como anotaciones en las celdas
# Recorre cada celda de la matriz de correlación
for i in range(len(corr)):
    for j in range(len(corr)):
        # 'round' redondea el valor de correlación a dos decimales
        # 'ha' y 'va' establecen la alineación horizontal y vertical del texto
        # 'color' define el color del texto
        plt.text(j, i, round(corr.iloc[i, j], 2), ha='center', va='center', color='black')

# Añade un título al gráfico
plt.title("Gráfico de Calor")

# Etiqueta los ejes x e y con los nombres de las columnas y filas de la matriz de correlación
# 'rotation' gira las etiquetas del eje x 45 grados para mayor legibilidad
plt.xticks(range(len(corr.columns)), corr.columns, rotation=45)
plt.yticks(range(len(corr.index)), corr.index)

# Muestra el gráfico en pantalla
plt.show()

"""# Analizando datos

"""

#Probabilidad de lluvia por ciudad
data_frame.groupby('Location')['RainTomorrow'].value_counts()

# Filtramos el DataFrame para obtener solo las filas donde la columna 'RainTomorrow' tiene el valor 'Yes'
filtered_data = data_frame[data_frame.RainTomorrow == 'Yes']

# Agrupamos los datos filtrados por la columna 'Date' y contamos el número de registros en cada grupo
grouped_data = filtered_data.groupby('Date').count()

# La variable 'grouped_data' ahora contiene el recuento de cuántas veces se predice lluvia para cada fecha
print(grouped_data)

# Agrupar los datos por fecha y sumar la cantidad de lluvia caída en cada día
rainfall_por_dia = data_frame.groupby('Date')['Rainfall'].sum().reset_index()

# Ordenar los resultados por cantidad de lluvia de manera descendente
rainfall_por_dia = rainfall_por_dia.sort_values(by='Rainfall', ascending=False)

#Imprime los datos anteriores
print(rainfall_por_dia)

# Convertir la columna 'Date' al tipo de datos de fecha
data_frame['Date'] = pd.to_datetime(data_frame['Date'])

# Extraer el año de cada fecha
data_frame['Year'] = data_frame['Date'].dt.year

# Sumar la cantidad de lluvia caída por año
rainfall_por_año = data_frame.groupby('Year')['Rainfall'].sum().reset_index()

# Ordenar los resultados por cantidad de lluvia de manera descendente
rainfall_por_año = rainfall_por_año.sort_values(by='Rainfall', ascending=False)

#imprime RAINFALL por AÑO
print(rainfall_por_año)

# Extraer el día de la semana en nombre
data_frame['Weekday'] = data_frame['Date'].dt.strftime('%A')

# Sumar la cantidad de lluvia caída por día de la semana
rainfall_por_dia = data_frame.groupby('Weekday')['Rainfall'].sum().reset_index()

# Ordenar los resultados por cantidad de lluvia de manera descendente
rainfall_por_dia = rainfall_por_dia.sort_values(by='Rainfall', ascending=False)

#imprime rainfall por dia
print(rainfall_por_dia)

"""# Preparación de los Datos

"""

# Leemos el archivo CSV "weatherAUS.csv" y cargamos los datos en un DataFrame
data_frame = pd.read_csv("weatherAUS.csv")

# Mostramos las primeras 5 filas del DataFrame para inspeccionar los datos
print(data_frame.head())

"""# Valores Atípicos"""

# Creando subset con solo con días donde si llovió
data_Rainfall = data_frame[(data_frame['Rainfall'] > 0) & (data_frame['RainToday'] == 'Yes')]
data_Rainfall.shape

# Creando un segmento de montos de lluvia en mm
monto_segm = pd.cut(data_Rainfall['Rainfall'], [0, 10, 20, 30, 40, 50, 60,
100, 200])

# Creando el gráfico de barras

# Usamos pd.value_counts para contar la frecuencia de cada valor en 'monto_segm'
# y luego creamos un gráfico de barras a partir de esos conteos.
plot = pd.value_counts(monto_segm).plot(kind='bar', title='Cantidades de lluvia por día')

# Establecemos la etiqueta del eje y del gráfico de barras como 'Lluvia en mm'
plot.set_ylabel('Lluvia en mm')

# Establecemos la etiqueta del eje x del gráfico de barras como 'Días de lluvia'
plot.set_xlabel('Días de lluvia')

# Mostramos el gráfico en pantalla
plt.show()

# Asumimos que 'monto_segm' es una serie de pandas que contiene datos de lluvia en mm
# Esta línea cuenta la frecuencia de cada valor en 'monto_segm' y devuelve una serie
# donde el índice son los valores únicos y los valores son las frecuencias de esos valores
conteos = pd.value_counts(monto_segm)

# Mostramos los conteos
print(conteos)

# Creamos un gráfico de caja utilizando los datos de lluvia
# Asumimos que 'data_Rainfall' es un DataFrame y 'Rainfall' es una columna que contiene los datos de lluvia
plt.boxplot(list(data_Rainfall['Rainfall']))

# Establecemos el título del gráfico
plt.title('Cantidad de lluvia por día')

# Mostramos el gráfico en pantalla
plt.show()

"""# Valores Nulos"""

# Valores nulos
for feature in data_frame.columns:
  print('Total de valores nulos de', feature, '=', data_frame[feature].isna().sum())

# Agrupación de columnas por tipos de datos
tipos = data_frame.columns.to_series().groupby(data_frame.dtypes).groups

# Conociendo la lista de columnas categóricas
ctext = tipos[np.dtype('object')]
len(ctext)

# Conociendo la lista de columnas numéricas
columnas = data_frame.columns
cnum = list(set(columnas) - set(ctext))
len(cnum)

# Completar valores faltantes en datos cuantitativos
for columna in cnum:
    mean = data_frame[columna].mode()[0]
    data_frame[columna] = data_frame[columna].fillna(mean)

# Completar valores faltantes en datos cualitativos

for columna in ctext:
    mode = data_frame[columna].mode()[0]
    data_frame[columna] = data_frame[columna].fillna(mode)

# Comprobar nulos
data_frame.isnull().any().any()

"""

> Añadir blockquote






# Separar Columnas X & Y
"""

# Seleccionar todas las columnas excepto Date, Location y RainTomorrow
X = data_frame.iloc[:, 2:-1].values

# Seleccionar la última columna (RainTomorrow)
y = data_frame.iloc[:, -1].values

# Crear un DataFrame con las primeras 10 filas de X para visualización
pd.DataFrame(X).head(10)

# Crear un DataFrame a partir de la matriz y (que contiene la columna 'RainTomorrow')
# y mostrar las primeras 5 filas para visualización
pd.DataFrame(y).head(5)

#Transformar valores nulos por 0
X_df = pd.DataFrame(X)

y_df = pd.DataFrame(y)

# Reemplazar valores NaN con 0
X_df.fillna(0, inplace=True)


# Eliminar las columnas categóricas
X_df = X_df.select_dtypes(exclude=['object'])

# Convertir de nuevo a array de numpy
X = X_df.values

# Visualizar las primeras filas del array modificado
print(pd.DataFrame(X).head(10))

# Eliminar columnas no numéricas del DataFrame
X = data_frame.select_dtypes(include=['float64', 'int64']).values

# Crear un DataFrame a partir de la matriz y (que contiene la columna 'RainTomorrow'),
# seleccionar la primera columna ([0]) y luego obtener los valores únicos
pd.DataFrame(y)[0].unique()

from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

values = array(y)
print('Valores:',values)
# integer encode
label_encoder = LabelEncoder()
integer_encoded = label_encoder.fit_transform(values)
y = integer_encoded
print('y:',integer_encoded)

"""# Escalado de datos

"""

from sklearn.preprocessing import StandardScaler

# Asumiendo que 'X' ya está definido y has eliminado las columnas categóricas
X = X[:, 1:]

# Aplicar StandardScaler a columnas numéricas
sc = StandardScaler()
scaled_data = sc.fit_transform(X)

#Revisar distribucion de observaciones respecto de la variable que se usará para su clasificación

print(data_frame.groupby('RainTomorrow').size())

import matplotlib.pyplot as plt

# Conteo de las clases de la variable objetivo 'RainTomorrow'
no_llueve = data_frame[data_frame['RainTomorrow'] == 'No'].shape[0]
llueve = data_frame[data_frame['RainTomorrow'] == 'Yes'].shape[0]

# Cálculo de los porcentajes
total = no_llueve + llueve
porcentaje_no_llueve = (no_llueve / total) * 100
porcentaje_llueve = (llueve / total) * 100

# Etiquetas para las clases
labels = ['No llueve mañana', 'Llueve mañana']

# Valores para las clases
sizes = [porcentaje_no_llueve, porcentaje_llueve]

# Colores para cada clase
colors = ['#ff9999','#66b3ff']

# Creación del gráfico de torta
plt.figure(figsize=(6, 6))
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)

# Ajustes adicionales
plt.title('Porcentaje de probabilidad de lluvia')

# Mostrar el gráfico
plt.axis('equal')
plt.show()

"""# `Modelos Supervisados`

# **Modelo Bayesiano/Naive_bayes**
"""

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB

# Separar train de test para X e y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=29)
y_train = y_train.astype(int)
y_test = y_test.astype(int)

# Crear el modelo Naive Bayes Gaussiano
modelo = GaussianNB()

# Entrenar el modelo
modelo.fit(X_train, y_train)

# Validación del modelo
y_pred = modelo.predict(X_test)

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import precision_score

# Calcular la precisión del modelo
precision = precision_score(y_test, y_pred)

# Configurar la figura y los ejes
plt.figure(figsize=(6, 4))

# Configurar barras
bar_width = 0.4
bars = ['Precisión']
y_pos = np.arange(len(bars))
values = [precision]

# Crear gráfico de barras
plt.bar(y_pos, values, width=bar_width, color='skyblue', align='center')

# Añadir valores numéricos a las barras
for i, value in enumerate(values):
    plt.text(i, value + 0.01, f'{value:.2f}', ha='center', va='bottom', fontsize=12)

# Ajustar ejes y etiquetas
plt.xticks(y_pos, bars)
plt.ylabel('Precisión')
plt.title('Precisión del Modelo Bayesiano/Naive_bayes')

plt.ylim(0, 1)  # Asegurar que el eje y comience desde 0 hasta 1

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Suponiendo que ya tienes y_pred y y_test definidos

# Calcular la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)

# Crear la visualización de la matriz de confusión
labels = ['No llueve', 'Llueve']  # Definir las etiquetas de las clases
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)

# Configurar las dimensiones de la figura
plt.figure(figsize=(8, 6))

# Mostrar la matriz de confusión
disp.plot(cmap=plt.cm.Blues)

# Añadir título y etiquetas
plt.title('Matriz de Confusión')
plt.xlabel('Predicciones')
plt.ylabel('Valores verdaderos')

# Mostrar el gráfico
plt.show()

import plotly.graph_objects as go
from sklearn.metrics import accuracy_score, f1_score, recall_score

# Supongamos que y_test y y_pred están definidos

# Calcular métricas
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Crear un DataFrame para visualización
metrics_df = pd.DataFrame({
    'Métrica': ['Exactitud', 'Puntaje F1', 'Recall'],
    'Puntaje': [accuracy, f1, recall]
})

# Crear gráfico de barras horizontal
fig = go.Figure(go.Bar(
    x=metrics_df['Puntaje'],
    y=metrics_df['Métrica'],
    text=metrics_df['Puntaje'].round(4),
    textposition='auto',
    orientation='h'
))

fig.update_layout(
    title='Métricas de Evaluación del Modelo',
    xaxis_title='Puntaje',
    yaxis_title='Métrica',
    template='plotly_white'
)

fig.show()

"""# **Modelo de arbol de decisiones**

"""

from sklearn.tree import DecisionTreeClassifier

# Creación del modelo de Árbol de Decisión con hiperparámetros ajustados
modelo_arbol = DecisionTreeClassifier(
    random_state=29,
    max_depth=5,             # Limita la profundidad del árbol a 5 niveles
    min_samples_split=10,    # Un nodo se divide si tiene al menos 10 muestras
    min_samples_leaf=5,      # Cada hoja debe tener al menos 5 muestras
    max_features='sqrt',     # Utiliza la raíz cuadrada del número de características
    criterion='entropy'      # Usa la entropía como criterio de calidad
)

# Entrenamiento del modelo
modelo_arbol.fit(X_train, y_train)

# Validación del modelo
y_pred_arbol = modelo_arbol.predict(X_test)

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Calcular la matriz de confusión del Árbol de Decisión
matriz_arbol = confusion_matrix(y_test, y_pred_arbol)

# Crear la visualización de la matriz de confusión
labels = ['No llueve', 'Llueve']  # Definir las etiquetas de las clases
disp = ConfusionMatrixDisplay(confusion_matrix=matriz_arbol, display_labels=labels)

# Configurar las dimensiones de la figura
plt.figure(figsize=(8, 6))

# Mostrar la matriz de confusión
disp.plot(cmap=plt.cm.Blues)

# Añadir título y etiquetas
plt.title('Matriz de Confusión - Árbol de Decisión')
plt.xlabel('Predicciones')
plt.ylabel('Valores verdaderos')

# Mostrar el gráfico
plt.show()

import plotly.graph_objects as go
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score

# Supongamos que y_test y y_pred_arbol están definidos

# Calcular métricas
accuracy_arbol = accuracy_score(y_test, y_pred_arbol)
f1_arbol = f1_score(y_test, y_pred_arbol)
recall_arbol = recall_score(y_test, y_pred_arbol)
precision_arbol = precision_score(y_test, y_pred_arbol)

# Crear un DataFrame para visualización
metrics_df = pd.DataFrame({
    'Metric': ['Accuracy', 'F1 Score', 'Recall', 'Precision'],
    'Score': [accuracy_arbol, f1_arbol, recall_arbol, precision_arbol]
})

# Crear gráfico de barras horizontal
fig = go.Figure(go.Bar(
    x=metrics_df['Score'],
    y=metrics_df['Metric'],
    text=metrics_df['Score'].round(4),
    textposition='auto',
    orientation='h'
))

fig.update_layout(
    title='Métricas del Modelo de Árbol de Decisión',
    xaxis_title='Score',
    yaxis_title='Métrica',
    template='plotly_white'
)

fig.show()

"""# **Modelo Random Forest**

"""

# Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, recall_score

# Crear el modelo Random Forest
modelo_rf = RandomForestClassifier(random_state=29,max_depth =1)

# Entrenar el modelo
modelo_rf.fit(X_train, y_train)

# Realizar predicciones
y_pred_rf = modelo_rf.predict(X_test)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, recall_score

# Supongamos que 'y_test' y 'y_pred_rf' ya están definidos

# Calcular métricas
matriz_rf = confusion_matrix(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
exactitud_rf = accuracy_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)

# Configurar el estilo de seaborn para mejorar la apariencia
sns.set(style="whitegrid")

# Configurar la figura y los ejes
plt.figure(figsize=(14, 6))

# Subplot para la matriz de confusión
plt.subplot(1, 2, 1)
sns.heatmap(matriz_rf, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['No Llueve', 'Llueve'],
            yticklabels=['No Llueve', 'Llueve'])
plt.title('Matriz de Confusión del Modelo Random Forest')
plt.xlabel('Valores Predichos')
plt.ylabel('Valores Verdaderos')

# Subplot para las métricas
plt.subplot(1, 2, 2)
metrics = ['Precision', 'Accuracy', 'F1 Score', 'Recall']
scores = [precision_rf, exactitud_rf, f1_rf, recall_rf]
sns.barplot(x=scores, y=metrics, palette='Blues_d')
plt.xlim(0, 1)
plt.title('Métricas de Evaluación del Modelo Random Forest')

# Agregar etiquetas numéricas en las barras
for index, value in enumerate(scores):
    plt.text(value, index, f'{value:.2f}', va='center')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

# Imprimir métricas
print("Resultados para Random Forest:")
print(f'Precisión: {precision_rf:.2f}')
print(f'Exactitud: {exactitud_rf:.2f}')
print(f'F1 Score: {f1_rf:.2f}')
print(f'Recall: {recall_rf:.2f}')

"""# **Modelo K-Nearest Neighbors**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, recall_score
import matplotlib.pyplot as plt
import seaborn as sns

# Crear modelo KNN
modelo_knn = KNeighborsClassifier(n_neighbors=5)  # Ejemplo de configuración de número de vecinos

# Entrenar el modelo
modelo_knn.fit(X_train, y_train)

# Realizar predicciones en los datos de prueba
y_pred_knn = modelo_knn.predict(X_test)

# Calcular métricas de evaluación
matriz_knn = confusion_matrix(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn)
exactitud_knn = accuracy_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn)
recall_knn = recall_score(y_test, y_pred_knn)

# Configurar el estilo de seaborn para mejorar la apariencia
sns.set(style="whitegrid")

# Configurar la figura y los ejes
plt.figure(figsize=(14, 6))

# Subplot para la matriz de confusión
plt.subplot(1, 2, 1)
sns.heatmap(matriz_knn, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['No Llueve', 'Llueve'],
            yticklabels=['No Llueve', 'Llueve'])
plt.title('Matriz de Confusión del Modelo K-Nearest Neighbors')
plt.xlabel('Valores Predichos')
plt.ylabel('Valores Verdaderos')

# Subplot para las métricas
plt.subplot(1, 2, 2)
metrics = ['Precision', 'Accuracy', 'F1 Score', 'Recall']
scores = [precision_knn, exactitud_knn, f1_knn, recall_knn]
sns.barplot(x=scores, y=metrics, palette='Blues_d')
plt.xlim(0, 1)
plt.title('Métricas de Evaluación del Modelo K-Nearest Neighbors')

# Agregar etiquetas numéricas en las barras
for index, value in enumerate(scores):
    plt.text(value, index, f'{value:.2f}', va='center')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

# Mostrar métricas
print("Resultados para K-Nearest Neighbors:")
print(f'Precisión: {precision_knn:.2f}')
print(f'Exactitud: {exactitud_knn:.2f}')
print(f'F1 Score: {f1_knn:.2f}')
print(f'Recall: {recall_knn:.2f}')

"""# **Modelo SVM**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, recall_score

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Escalar los datos
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Entrenar el modelo SVM
modelo_svm = SVC()
modelo_svm.fit(X_train_scaled, y_train)

# Realizar predicciones
y_pred_svm = modelo_svm.predict(X_test_scaled)

from tabulate import tabulate
import joblib

# Calcular métricas de evaluación
accuracy = accuracy_score(y_test, y_pred_svm)
precision = precision_score(y_test, y_pred_svm)
recall = recall_score(y_test, y_pred_svm)
f1 = f1_score(y_test, y_pred_svm)
conf_matrix = confusion_matrix(y_test, y_pred_svm)

# Configurar el estilo de seaborn para mejorar la apariencia
sns.set(style="whitegrid")

# Configurar la figura y los ejes
plt.figure(figsize=(8, 6))

# Crear matriz de confusión utilizando seaborn
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['Predicted No', 'Predicted Yes'],
            yticklabels=['Actual No', 'Actual Yes'])

plt.title('Matriz de Confusión - Support Vector Machine (SVM)')
plt.xlabel('Valores Predichos')
plt.ylabel('Valores Verdaderos')

plt.show()

# Definir las métricas como una lista de tuplas
metrics_data = [
    ('Exactitud (Accuracy)', f'{accuracy * 100:.2f}%'),
    ('Precisión (Precision)', f'{precision:.2f}'),
    ('Recall', f'{recall:.2f}'),
    ('Puntuación F1 (F1 Score)', f'{f1:.2f}')
]

# Imprimir las métricas en forma de tabla
print("\nResultados para Support Vector Machine (SVM):\n")
print(tabulate(metrics_data, headers=['Métrica', 'Valor'], tablefmt='fancy_grid'))


# Guardar el modelo SVM
joblib.dump(modelo_svm, 'modelo_svm.pkl')

# Guardar el scaler
joblib.dump(scaler, 'scaler.pkl')

"""#` Modelos no supervisados`

# **K-Means (metodo codo)**
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn import datasets

# Cargar el conjunto de datos (ejemplo con Iris dataset)
iris = datasets.load_iris()
X = iris.data

# Lista para almacenar los valores de la inercia
inertia = []

# Número de clusters a probar
k_range = range(1, 11)

# Calcular la inercia para cada valor de k
for k in k_range:
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(X)
    inertia.append(kmeans.inertia_)

# Graficar la inercia en función del número de clusters
plt.figure(figsize=(8, 6))
plt.plot(k_range, inertia, marker='o', linestyle='-', color='b')
plt.xlabel('Número de Clusters (k)')
plt.ylabel('Inercia')
plt.title('Valor de la Inercia en función del número de clusters')
plt.xticks(k_range)
plt.grid(True)
plt.show()

"""# **Panel de control**"""

#instalacion previa para la visualizacion del dashboard
!pip install dash pandas plotly scikit-learn joblib
!pip install pickle5
!pip install pandas plotly dash

import pandas as pd
from dash import Dash, dcc, html, Input, Output
import plotly.express as px
import joblib


# Cargar el modelo y el escalador
modelo_svm = joblib.load('modelo_svm.pkl')
scaler = joblib.load('scaler.pkl')

# Crear la aplicación Dash
app = Dash(__name__)

# Definir el diseño de la aplicación
app.layout = html.Div([
    html.H1("Panel de Control del Clima"),

    dcc.Dropdown(
        id='location-dropdown',
        options=[{'label': loc, 'value': loc} for loc in data_frame['Location'].unique()],
        value='Sydney',
        style={'width': '50%'}
    ),

    dcc.Graph(id='rainfall-graph'),
    dcc.Graph(id='temp-graph'),
    dcc.Graph(id='prediction-graph')
])

# Definir callback para actualizar gráficos
@app.callback(
    [Output('rainfall-graph', 'figure'),
     Output('temp-graph', 'figure'),
     Output('prediction-graph', 'figure')],
    [Input('location-dropdown', 'value')]
)
def update_graphs(selected_location):
    filtered_df = data_frame[data_frame['Location'] == selected_location]

    if filtered_df.empty:
        empty_fig = px.line(title='No hay datos disponibles para esta ubicación')
        return empty_fig, empty_fig, empty_fig

    # Gráfico de lluvia
    rainfall_fig = px.line(filtered_df, x='Date', y='Rainfall', title='Lluvia a lo largo del Tiempo')

    # Gráfico de temperatura
    temp_fig = px.line(filtered_df, x='Date', y='MaxTemp', title='Temperatura Máxima a lo largo del Tiempo')

    # Preprocesamiento de datos para predicción
    features = filtered_df[['MinTemp', 'MaxTemp', 'Rainfall', 'WindSpeed3pm', 'Humidity3pm']].dropna()

    if not features.empty:
        # Aplicar el escalador
        features_scaled = scaler.transform(features)

        # Realizar predicciones
        predictions = modelo_svm.predict(features_scaled)

        # Añadir las predicciones al DataFrame
        filtered_df = filtered_df.loc[features.index]
        filtered_df['Predicción de Lluvia Mañana'] = predictions

        # Gráfico de predicción
        prediction_fig = px.scatter(filtered_df, x='Date', y='Predicción de Lluvia Mañana', title='Predicción de Lluvia Mañana')

        return rainfall_fig, temp_fig, prediction_fig

    else:
        empty_fig = px.line(title='No hay suficientes datos para mostrar')
        return empty_fig, empty_fig, empty_fig

# Ejecutar la aplicación
if __name__ == '__main__':
    app.run_server(debug=True)

import pandas as pd
import plotly.express as px
import joblib

# Cargar el conjunto de datos
data_frame = pd.read_csv("weatherAUS.csv")
data_frame['Date'] = pd.to_datetime(data_frame['Date'])

# Suponiendo que tienes un modelo SVM entrenado y un scaler cargados previamente
modelo_svm = joblib.load('modelo_svm.pkl')
scaler = joblib.load('scaler.pkl')

# Suponiendo que 'modelo_svm' y 'scaler' son modelos y escaladores adecuados para predecir la lluvia
# Realizar predicciones sobre el conjunto de datos para obtener los niveles de lluvia predichos
# Aquí asumimos que se realiza alguna preparación y predicción similar a tu flujo de trabajo

# Crear una tabla de ciudades con su nivel de lluvia promedio (ejemplo ficticio)
promedio_lluvia_ciudades = data_frame.groupby('Location')['Rainfall'].mean().reset_index()

# Crear el mapa interactivo con Plotly Express
fig = px.scatter_geo(promedio_lluvia_ciudades, locations='Location', locationmode='country names',
                     color='Rainfall', size='Rainfall', projection='natural earth',
                     title='Ciudades con Más Lluvia', hover_name='Location', size_max=50)

fig.update_geos(showcoastlines=True, coastlinecolor="Black", showland=True, landcolor="LightGreen",
                showocean=True, oceancolor="LightBlue", showlakes=True, lakecolor="Blue")

# Mostrar el mapa
fig.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Cargar datos de ejemplo (Iris dataset)
iris = load_iris()
X = iris.data
y = iris.target

# Dividir datos en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Entrenar modelos SVM y KNN para ejemplo
modelo_svm = SVC(kernel='linear')
modelo_svm.fit(X_train, y_train)

modelo_knn = KNeighborsClassifier(n_neighbors=5)
modelo_knn.fit(X_train, y_train)

# Realizar predicciones
y_pred_svm = modelo_svm.predict(X_test)
y_pred_knn = modelo_knn.predict(X_test)

# Calcular métricas para SVM
accuracy_svm = accuracy_score(y_test, y_pred_svm)
precision_svm = precision_score(y_test, y_pred_svm, average='weighted')
recall_svm = recall_score(y_test, y_pred_svm, average='weighted')
f1_svm = f1_score(y_test, y_pred_svm, average='weighted')
matriz_confusion_svm = confusion_matrix(y_test, y_pred_svm)

# Calcular métricas para KNN
accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn, average='weighted')
recall_knn = recall_score(y_test, y_pred_knn, average='weighted')
f1_knn = f1_score(y_test, y_pred_knn, average='weighted')
matriz_confusion_knn = confusion_matrix(y_test, y_pred_knn)

# Configurar el estilo de seaborn para mejorar la apariencia
sns.set(style="whitegrid")

# Crear subplots para las visualizaciones
fig, axs = plt.subplots(2, 2, figsize=(12, 10))

# Matriz de confusión para SVM
sns.heatmap(matriz_confusion_svm, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axs[0, 0])
axs[0, 0].set_title('Matriz de Confusión - SVM')
axs[0, 0].set_xlabel('Etiqueta Predicha')
axs[0, 0].set_ylabel('Etiqueta Verdadera')

# Matriz de confusión para KNN
sns.heatmap(matriz_confusion_knn, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axs[0, 1])
axs[0, 1].set_title('Matriz de Confusión - KNN')
axs[0, 1].set_xlabel('Etiqueta Predicha')
axs[0, 1].set_ylabel('Etiqueta Verdadera')

# Distribución de las predicciones vs datos reales para SVM
sns.histplot(y_test, bins=10, kde=True, color='blue', label='Etiquetas Verdaderas', ax=axs[1, 0])
sns.histplot(y_pred_svm, bins=10, kde=True, color='orange', label='Etiquetas Predichas', ax=axs[1, 0])
axs[1, 0].set_title('Distribución de Predicciones vs Datos Reales - SVM')
axs[1, 0].set_xlabel('Clase')
axs[1, 0].set_ylabel('Conteo')
axs[1, 0].legend()

# Distribución de las predicciones vs datos reales para KNN
sns.histplot(y_test, bins=10, kde=True, color='blue', label='Etiquetas Verdaderas', ax=axs[1, 1])
sns.histplot(y_pred_knn, bins=10, kde=True, color='green', label='Etiquetas Predichas', ax=axs[1, 1])
axs[1, 1].set_title('Distribución de Predicciones vs Datos Reales - KNN')
axs[1, 1].set_xlabel('Clase')
axs[1, 1].set_ylabel('Conteo')
axs[1, 1].legend()

# Ajustar espaciado entre subplots
plt.tight_layout()

# Mostrar las métricas
print("Métricas para SVM:")
print(f'Exactitud (Accuracy): {accuracy_svm:.2f}')
print(f'Precisión (Precision): {precision_svm:.2f}')
print(f'Recall: {recall_svm:.2f}')
print(f'Puntuación F1 (F1 Score): {f1_svm:.2f}')

print("\nMétricas para KNN:")
print(f'Exactitud (Accuracy): {accuracy_knn:.2f}')
print(f'Precisión (Precision): {precision_knn:.2f}')
print(f'Recall: {recall_knn:.2f}')
print(f'Puntuación F1 (F1 Score): {f1_knn:.2f}')

# Mostrar las visualizaciones
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import plotly.express as px

# Cargar datos de ejemplo (Iris dataset)
iris = load_iris()
X = iris.data
y = iris.target

# Dividir datos en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Entrenar modelo SVM para ejemplo
modelo_svm = SVC(kernel='linear')
modelo_svm.fit(X_train, y_train)

# Realizar predicciones
y_pred_svm = modelo_svm.predict(X_test)

# Crear DataFrame para visualización
df_visualizacion = pd.DataFrame({
    'Feature1': X_test[:, 0],
    'Feature2': X_test[:, 1],
    'Prediction': y_pred_svm,
    'Actual': y_test
})

# Mapeo de nombres de clases para mejor legibilidad
clase_map = {0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'}

# Convertir los valores numéricos de predicción y clase real a nombres de clase
df_visualizacion['Prediction'] = df_visualizacion['Prediction'].map(clase_map)
df_visualizacion['Actual'] = df_visualizacion['Actual'].map(clase_map)

# Mapa de dispersión interactivo con Plotly Express
fig = px.scatter(df_visualizacion, x='Feature1', y='Feature2', color='Prediction',
                 symbol='Actual', symbol_map={clase: i for i, clase in enumerate(clase_map.values())},
                 labels={'Prediction': 'Clase Predicha', 'Actual': 'Clase Real'},
                 title='Clases Predichas vs Clases Reales (SVM)',
                 category_orders={'symbol': list(clase_map.values())})
fig.show()